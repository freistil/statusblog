---
status: resolved
title: Storage cluster problem
severity: high
tags: storage
category: Hosting
date: 2013-03-09 21:50 UTC
published: true
layout: status
---

#### ISSUE:

We are experiencing a problem with storage cluster stor02 that impacts the operation of multiple websites. 


#### CAUSE:

Hardware failure. 


#### TIMELINE:

* [2013-03-09 21:50 UTC] Incident opened. 
* [2013-03-09 21:51 UTC] One of two storage cluster nodes is down.
* [2013-03-09 21:57 UTC] After a hardware reset, the storage node came back up. Services start to recover.
* [2013-03-09 22:02 UTC] All dependent systems are working normal again.
* [2013-03-10 00:40 UTC] Incident reoponend. The same stor node is offline again.
* [2013-03-10 00:45 UTC] Services are recovering immediately after a hardware reset of the storage node.
* [2013-03-10 02:19 UTC] The server failed again. We triggered a hardware reset and will take the node out of the cluster to prevent further disruptions.
* [2013-03-10 02:37 UTC] We found multiple indications of a hardware problem. We asked the datacenter team to run an extensive hardware check on the failed node.
* [2013-03-10 02:53 UTC] Hardware check has started.
* [2013-03-10 17:50 UTC] The hardware check showed two problematic disks that need to be replaced. We manually started RAID recovery of one to a spare disk; the other disk needs to recover after replacement. Additionally, we found evidence of network driver issues in the Linux kernel that we're going to tackle with an alternative driver.
* [2013-03-11 03:48 UTC] Both disks have been replaced. Recovery to spare has already finished; the second disk is recovering now.
* [2013-03-11 11:33 UTC] The disk array has fully recovered. Because we anticipate elevated load from the cluster filesystem resynchronisation, we're going to add the node to the storage cluster after 22:00 UTC.
* [2013-03-11 22:35 UTC] We're taking the storage node back online. This could result in temporary connection issues for some storage-intensive websites.
* [2013-03-12 23:00 UTC] The storage cluster is fully operational again; its  nodes are synchronising in the background.
* [2013-03-12 21:25 UTC] Incident closed. We'll proceed with the necessary problem management.
